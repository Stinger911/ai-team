log_file_path: "role_calls.log"
openai:
  default_apiurl: "https://api.openai.com/v1"
  apikey: "YOUR_OPENAI_API_KEY"
  models:
    gpt-3:
      model: gpt-3
      temperature: 0.7
      max_tokens: 1000
    gpt35-turbo-cloud:
      model: gpt-3.5-turbo
      temperature: 0.7
      max_tokens: 1000
    gpt-4-code-focused:
      model: gpt-4
      temperature: 0.2
      max_tokens: 1000
    gpt-3-5-turbo-local:
      model: gpt-3.5-turbo
      temperature: 0.7
      max_tokens: 1000
      apiurl: "http://localhost:8000/v1"
      apikey: "NO_KEY_NEEDED"
    gpt-3-5-turbo:
      model: gpt-3.5-turbo
      temperature: 0.7
      max_tokens: 1000
      apiurl: "http://mock"
      apikey: "NO_KEY_NEEDED"

gemini:
  apikey: "test" # Provider-level API key for tests
  apiurl: "http://mock" # Provider-level URL for tests
  models:
    gemini-pro-standard:
      model: gemini-pro
      temperature: 0.9
      max_tokens: 1000
    gemini-pro-creative:
      model: gemini-pro
      temperature: 1.0
      top_p: 0.9
      max_tokens: 1000
    gemini-2.5-flash:
      model: gemini-2.5-flash
      temperature: 0.7
      max_tokens: 1000
    gemini-25-flash:
      model: gemini-2.5-flash
      temperature: 0.7
      max_tokens: 1000
    gemini-2:
      model: gemini-2
      temperature: 0.7
      max_tokens: 1000

ollama:
  apiurl: "http://localhost:11434" # Provider-level URL
  models:
    llama2-7b:
      model: llama2:7b
    codellama-34b:
      model: codellama:34b

tools:
  - name: "write_file"
    description: "Writes content to a specified file."
    command_template: "echo \"write_file\""
    arguments:
      - name: "filePath"
        type: "string"
        description: "Path to the file to write."
      - name: "content"
        type: "string"
        description: "Content to write."
  - name: "run_command"
    description: "Executes a shell command."
    command_template: "echo \"run_command\""
    arguments:
      - name: "command"
        type: "string"
        description: "Shell command to execute."
  - name: "apply_patch"
    description: "Applies a patch to a file."
    command_template: "echo \"apply_patch\""
    arguments:
      - name: "filePath"
        type: "string"
        description: "Path to the file to patch."
      - name: "patchContent"
        type: "string"
        description: "Patch content."
roles:
  coder:
    model_provider: openai
    model_name: gpt-4-code-focused # Reference to model definition
    prompt: "Write code for {{.task}}"
  local_coder:
    model_provider: openai
    model_name: gpt-3-5-turbo-local # Reference to local model
    prompt: "Write code (using local model) for {{.task}}"
  writer:
    model_provider: gemini
    model_name: gemini-pro-creative
    prompt: "Write documentation for {{.task}}"
  analist:
    model_provider: gemini
    model_name: gemini-25-flash
    prompt: "analist prompt"
  architect:
    model_provider: gemini
    model_name: gemini-pro-standard
    prompt: "architect prompt"
  tester:
    model_provider: gemini
    model_name: gemini-pro
    prompt: |
      You are a tester. Review the following code: {{.code}} and provide
      test cases. Output your test cases as a tool call to 'write_file'.
      The 'file_path' argument should be 'test_cases.md'. The 'content'
      argument should be your test cases in markdown. Example:
      {\"tool_call\": {\"name\": \"write_file\", \"arguments\": {\"file_path\": \"test_cases.md\", \"content\": \"## Test Cases...\n\"}}}"

chains:
  design-code-document:
    steps:
      - role: architect
      - role: coder
      - role: writer
  design-code-test:
    steps:
      - role: architect
      - role: coder
      - role: tester
  full-development:
    steps:
      - role: architect
      - role: coder
      - role: tester
      - role: writer
